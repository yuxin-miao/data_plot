{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "import scipy.stats as st\n",
    "from scipy.optimize import curve_fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('term_project_overlay_data.csv').drop('overlay_error_x', axis = 1, inplace = False)\n",
    "OyOriginal = df[' overlay_error_y']\n",
    "df.drop(' overlay_error_y', axis = 1, inplace = True)\n",
    "dataOriginal = df.values\n",
    "df.rename(columns={' x': 'x'}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfout = df\n",
    "dfout['x2'] = df['x']*df['x']\n",
    "dfout['y2'] = df['y'] * df['y']\n",
    "dfout['xy'] = df['x'] * df['y']\n",
    "dfout['X2'] = df['X'] * df['X']\n",
    "dfout['Y2'] = df['Y'] * df['Y']\n",
    "dfout['XY'] = df['X'] * df['Y']\n",
    "dfout['0'] = 1\n",
    "dfout = dfout[['0', 'X', 'Y', 'XY', 'X2', 'Y2', 'x', 'y', 'xy', 'x2', 'y2']]\n",
    "dfout.to_csv(\"dataProcessed.csv\", index = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "250"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dfout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:1: FutureWarning: The signature of `Series.to_csv` was aligned to that of `DataFrame.to_csv`, and argument 'header' will change its default value from False to True: please pass an explicit value to suppress this warning.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "OyOriginal.to_csv(\"overlay_y.csv\", index = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "def funcOy (data, b0, b1, b2, b3, b4, b5, b6, b7, b8, b9, b10):\n",
    "    x, X, y, Y = data\n",
    "    return b0 + b1*X + b2*Y + b3*X*Y + b4*X*X + b5*Y*Y + b6*x + b7*y + b8*x*y + b9*x*x + b10*y*y;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "def funCal (popt, datai, yi):\n",
    "    x, X, y, Y = datai\n",
    "    ycal = popt[0] + popt[1]*X + popt[2]*Y + popt[3]*X*Y + popt[4]*X*X + popt[5]*Y*Y + popt[6]*x + popt[7]*y + popt[8]*x*y + popt[9]*x*x + popt[10]*y*y\n",
    "    return (yi - ycal)**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calPress (dataOriginal):\n",
    "    PRESS = 0;\n",
    "    for i in range(0, len(dataOriginal)):\n",
    "        data = np.delete(dataOriginal, i, 0)\n",
    "        data = data.T\n",
    "        Oy = np.delete(OyOriginal, i)\n",
    "        popt, pcov = curve_fit(funcOy, data, Oy)\n",
    "        PRESS = PRESS + funCal (popt, dataOriginal[i], OyOriginal[i])\n",
    "    \n",
    "    print(PRESS)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "101.61870540275662\n"
     ]
    }
   ],
   "source": [
    "calPress(dataOriginal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def print_regression_expr(coeffs, labels, Rs):\n",
    "    print(Rs)\n",
    "    if len(coeffs) == 1:\n",
    "        print(coeffs[0])\n",
    "        return\n",
    "    for i in range(len(coeffs)):\n",
    "        if labels[i] == '':\n",
    "            print(coeffs[i], end='')\n",
    "            continue\n",
    "        \n",
    "        if coeffs[i] > 0:\n",
    "            print('+', end='')\n",
    "        print(coeffs[i], end='')\n",
    "        print(labels[i], end='')\n",
    "            \n",
    "        if i == len(coeffs) - 1:\n",
    "            print()\n",
    "\n",
    "def output_regression(final_list, filename):\n",
    "    with open(filename, 'w+') as f:\n",
    "        for ind in range(len(final_list)):\n",
    "            f.write(str(final_list[ind][2]))\n",
    "            f.write('\\n')\n",
    "            coeffs = final_list[ind][0]\n",
    "            labels = final_list[ind][1]\n",
    "            if len(coeffs) == 1:\n",
    "                f.write(str(coeffs[0]))\n",
    "                f.write('\\n')\n",
    "                return\n",
    "            for i in range(len(coeffs)):\n",
    "                if labels[i] == '':\n",
    "                    f.write(str(coeffs[i]))\n",
    "                    continue\n",
    "                \n",
    "                if coeffs[i] > 0:\n",
    "                    f.write('+')\n",
    "                f.write(str(coeffs[i]))\n",
    "                f.write(str(labels[i]))\n",
    "                    \n",
    "                if i == len(coeffs) - 1:\n",
    "                    f.write('\\n')\n",
    "\n",
    "\n",
    "def cal_fit_result(all_preds, pred_labels, fit, n):\n",
    "    res = np.ones(n) * fit[0][0]\n",
    "    ind = 1\n",
    "    for ind in range(1, len(fit[1])):\n",
    "        res = res + all_preds[pred_labels.index(fit[1][ind])] * fit[0][ind]\n",
    "    return res\n",
    "\n",
    "\n",
    "def plot_curve(all_preds, pred_labels, Ox_fit, Oy_fit, Ox, Oy):\n",
    "    plt.scatter(all_preds[0] + all_preds[5] + Ox, all_preds[1] + all_preds[6] + Oy, marker='.', linewidth=1)\n",
    "    Ox_fitted = cal_fit_result(all_preds, pred_labels, Ox_fit, len(Ox))\n",
    "    Oy_fitted = cal_fit_result(all_preds, pred_labels, Oy_fit, len(Oy))\n",
    "    plt.scatter(all_preds[0] + all_preds[5] + Ox_fitted, all_preds[1] + all_preds[6] + Oy_fitted, marker='.', linewidth=1)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import csv\n",
    "\n",
    "row_num = 0\n",
    "Ox = np.array([])\n",
    "Oy = np.array([])\n",
    "x = np.array([])\n",
    "y = np.array([])\n",
    "X = np.array([])\n",
    "Y = np.array([])\n",
    "\n",
    "\n",
    "# Read raw data from .csv file\n",
    "with open('term_project_overlay_data.csv','r') as f:\n",
    "    reader = csv.reader(f)\n",
    "    for row in reader:\n",
    "        row_num += 1\n",
    "        if row_num == 1:\n",
    "            continue\n",
    "        Ox = np.append(Ox, float(row[0]))\n",
    "        Oy = np.append(Oy, float(row[1]))\n",
    "        x = np.append(x, float(row[2]))\n",
    "        X = np.append(X, float(row[3]))\n",
    "        y = np.append(y, float(row[4]))\n",
    "        Y = np.append(Y, float(row[5]))\n",
    "\n",
    "n = len(Ox)\n",
    "\n",
    "all_predictors = [X, Y, X*Y, X*X, Y*Y, x, y, x*y, x*x, y*y]\n",
    "pred_labels = ['X', 'Y', 'XY', 'X^2', 'Y^2', 'x', 'y', 'xy', 'x^2', 'y^2']\n",
    "pred_num = len(all_predictors)\n",
    "\n",
    "result_preds = []\n",
    "result_labels = []\n",
    "Rsquares = []\n",
    "\n",
    "def test_all_regressions(x_data, y_data, labels, depth):\n",
    "    if depth == 10:\n",
    "        x_mat = np.mat(x_data).T\n",
    "        y_mat = np.mat(y_data)\n",
    "        b = (x_mat.T * x_mat).I * x_mat.T * y_mat.T\n",
    "        result_preds.append(b)\n",
    "        result_labels.append(labels)\n",
    "        # Calculate R^2\n",
    "        SST = np.sum(np.power(y_mat - np.mean(y_mat), 2))\n",
    "        SSE = (y_mat.T - x_mat * b).T * (y_mat.T - x_mat * b)\n",
    "        Rsq = (SST - SSE) / SST\n",
    "        Rsquares.append(Rsq[0,0])\n",
    "    else:\n",
    "        tmp = list(labels)\n",
    "        tmp_x_data = list(x_data)\n",
    "        tmp.append(pred_labels[depth])\n",
    "        tmp_x_data.append(all_predictors[depth])\n",
    "        test_all_regressions(tmp_x_data, y_data, tmp, depth + 1)\n",
    "        test_all_regressions(list(x_data), y_data, list(labels), depth + 1)\n",
    "        \n",
    "\n",
    "# Fit Ox\n",
    "test_all_regressions([np.ones(n)], Ox, [''], 0)\n",
    "\n",
    "final_list = [[np.array(result_preds[i]).flatten(), np.array(result_labels[i]).flatten(), Rsquares[i]] for i in range(len(Rsquares))]\n",
    "final = list(sorted(final_list, key=lambda x: x[2], reverse=True))\n",
    "\n",
    "output_regression(final, 'Ox.txt')\n",
    "Ox_fit = final[0]\n",
    "\n",
    "# Fit Oy\n",
    "result_preds = []\n",
    "result_labels = []\n",
    "Rsquares = []\n",
    "\n",
    "test_all_regressions([np.ones(n)], Oy, [''], 0)\n",
    "\n",
    "final_list = [[np.array(result_preds[i]).flatten(), np.array(result_labels[i]).flatten(), Rsquares[i]] for i in range(len(Rsquares))]\n",
    "final = list(sorted(final_list, key=lambda x: x[2], reverse=True))\n",
    "\n",
    "output_regression(final, 'Oy.txt')\n",
    "Oy_fit = final[0]\n",
    "\n",
    "plot_curve(all_predictors, pred_labels, Ox_fit, Oy_fit, Ox, Oy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ordinary Least Square Method with Training and Test Set Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "linear model intercept: 0.7485286953336125\n",
      "linear model coeff:\n",
      "[ 0.00000000e+00  3.04014130e-03  3.97338613e-03  1.03852304e-05\n",
      "  5.72920217e-06 -1.69748997e-05  1.60371908e-02  1.45566852e-02\n",
      "  2.75898064e-04 -3.65549058e-03  2.72713620e-03]\n",
      "R-squared score (training): 0.457\n",
      "R-squared score (test): 0.141\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(dfout, OyOriginal,\n",
    "                                                   random_state = 0)\n",
    "linreg = LinearRegression().fit(X_train, y_train)\n",
    "\n",
    "print('linear model intercept: {}'\n",
    "     .format(linreg.intercept_))\n",
    "print('linear model coeff:\\n{}'\n",
    "     .format(linreg.coef_))\n",
    "print('R-squared score (training): {:.3f}'\n",
    "     .format(linreg.score(X_train, y_train)))\n",
    "print('R-squared score (test): {:.3f}'\n",
    "     .format(linreg.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ridge Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ridge regression linear model intercept: 0.7484596024496036\n",
      "ridge regression linear model coeff:\n",
      "[ 0.00000000e+00  3.03919844e-03  3.97283637e-03  1.03837731e-05\n",
      "  5.73346762e-06 -1.69738261e-05  1.59955609e-02  1.45452115e-02\n",
      "  2.76051384e-04 -3.65446276e-03  2.72715717e-03]\n",
      "R-squared score (training): 0.457\n",
      "R-squared score (test): 0.141\n",
      "Number of non-zero features: 10\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "X_train, X_test, y_train, y_test = train_test_split(dfout, OyOriginal,\n",
    "                                                   random_state = 0)\n",
    "\n",
    "linridge = Ridge(alpha=20.0).fit(X_train, y_train)\n",
    "\n",
    "print('ridge regression linear model intercept: {}'\n",
    "     .format(linridge.intercept_))\n",
    "print('ridge regression linear model coeff:\\n{}'\n",
    "     .format(linridge.coef_))\n",
    "print('R-squared score (training): {:.3f}'\n",
    "     .format(linridge.score(X_train, y_train)))\n",
    "print('R-squared score (test): {:.3f}'\n",
    "     .format(linridge.score(X_test, y_test)))\n",
    "print('Number of non-zero features: {}'\n",
    "     .format(np.sum(linridge.coef_ != 0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scaled data:\n",
      "ridge regression linear model intercept: 0.24083232615128025\n",
      "ridge regression linear model coeff:\n",
      "[ 0.          0.33502682  0.4021618   0.06921812  0.07011548 -0.1146341\n",
      "  0.11788948  0.17023391  0.02507628 -0.1905958   0.48167654]\n",
      "R-squared score (training): 0.333\n",
      "R-squared score (test): 0.196\n",
      "Number of non-zero features: 10\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "from sklearn.linear_model import Ridge\n",
    "X_train, X_test, y_train, y_test = train_test_split(dfout, OyOriginal,\n",
    "                                                   random_state = 0)\n",
    "\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "linridge = Ridge(alpha=20.0).fit(X_train_scaled, y_train)\n",
    "\n",
    "print('Scaled data:')\n",
    "print('ridge regression linear model intercept: {}'\n",
    "     .format(linridge.intercept_))\n",
    "print('ridge regression linear model coeff:\\n{}'\n",
    "     .format(linridge.coef_))\n",
    "print('R-squared score (training): {:.3f}'\n",
    "     .format(linridge.score(X_train_scaled, y_train)))\n",
    "print('R-squared score (test): {:.3f}'\n",
    "     .format(linridge.score(X_test_scaled, y_test)))\n",
    "print('Number of non-zero features: {}'\n",
    "     .format(np.sum(linridge.coef_ != 0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ridge regression: effect of alpha regularization parameter\n",
      "\n",
      "Alpha = 0.00\n",
      "num abs(coeff) > 0: 10, r-squared training: 0.46, r-squared test: 0.14\n",
      "[ 0.          0.86835556  1.03335853  0.22584521  0.11694353 -0.30575843\n",
      "  0.29253279  0.47846368  0.08233606 -0.32309871  0.75871912]\n",
      "-0.7158547772289222\n",
      "Alpha = 5.00\n",
      "num abs(coeff) > 0: 10, r-squared training: 0.43, r-squared test: 0.20\n",
      "[ 0.          0.62118221  0.73916096  0.14478558  0.10427008 -0.21398847\n",
      "  0.21267193  0.33293316  0.05417351 -0.27361404  0.66535951]\n",
      "-0.2804503221559539\n",
      "Alpha = 10.00\n",
      "num abs(coeff) > 0: 10, r-squared training: 0.40, r-squared test: 0.21\n",
      "[ 0.          0.48349633  0.57685202  0.10631876  0.09045139 -0.16563837\n",
      "  0.16753478  0.25367058  0.03949827 -0.23848147  0.59089461]\n",
      "-0.03318948331146865\n",
      "Alpha = 15.00\n",
      "num abs(coeff) > 0: 10, r-squared training: 0.36, r-squared test: 0.20\n",
      "[ 0.          0.39578498  0.47367494  0.08388826  0.07913985 -0.13541947\n",
      "  0.13835466  0.20406774  0.03077674 -0.21175754  0.53086921]\n",
      "0.12748507610734316\n",
      "Alpha = 20.00\n",
      "num abs(coeff) > 0: 10, r-squared training: 0.33, r-squared test: 0.20\n",
      "[ 0.          0.33502682  0.4021618   0.06921812  0.07011548 -0.1146341\n",
      "  0.11788948  0.17023391  0.02507628 -0.1905958   0.48167654]\n",
      "0.24083232615128025\n",
      "Alpha = 25.00\n",
      "num abs(coeff) > 0: 10, r-squared training: 0.31, r-squared test: 0.19\n",
      "[ 0.          0.29045325  0.34960977  0.05888637  0.0628487  -0.09942253\n",
      "  0.10272296  0.14575326  0.02108963 -0.17336625  0.44071008]\n",
      "0.3253438203976099\n",
      "Alpha = 30.00\n",
      "num abs(coeff) > 0: 10, r-squared training: 0.29, r-squared test: 0.18\n",
      "[ 0.          0.25635677  0.30932494  0.05122231  0.05690545 -0.08779234\n",
      "  0.091025    0.12725987  0.01815898 -0.1590408   0.40610205]\n",
      "0.3909188831789703\n",
      "Alpha = 35.00\n",
      "num abs(coeff) > 0: 10, r-squared training: 0.27, r-squared test: 0.17\n",
      "[ 0.          0.22943102  0.27744052  0.04531403  0.05196803 -0.07860525\n",
      "  0.0817241   0.11282157  0.015921   -0.14692984  0.37649653]\n",
      "0.44335666171603644\n",
      "Alpha = 40.00\n",
      "num abs(coeff) > 0: 10, r-squared training: 0.25, r-squared test: 0.16\n",
      "[ 0.          0.20762846  0.25156475  0.04062196  0.04780729 -0.07116154\n",
      "  0.07415015  0.101252    0.01416003 -0.13655004  0.35089143]\n",
      "0.4862896748644425\n",
      "Alpha = 45.00\n",
      "num abs(coeff) > 0: 10, r-squared training: 0.24, r-squared test: 0.15\n",
      "[ 0.          0.1896134   0.23013764  0.03680666  0.04425648 -0.06500649\n",
      "  0.06786212  0.09178353  0.01274059 -0.12755118  0.32853257]\n",
      "0.5221142341532394\n"
     ]
    }
   ],
   "source": [
    "print('Ridge regression: effect of alpha regularization parameter\\n')\n",
    "for this_alpha in range(0, 50, 5):\n",
    "    linridge = Ridge(alpha = this_alpha).fit(X_train_scaled, y_train)\n",
    "    r2_train = linridge.score(X_train_scaled, y_train)\n",
    "    r2_test = linridge.score(X_test_scaled, y_test)\n",
    "    num_coeff_bigger = np.sum(abs(linridge.coef_) > 0)\n",
    "    print('Alpha = {:.2f}\\nnum abs(coeff) > 0: {}, \\\n",
    "r-squared training: {:.2f}, r-squared test: {:.2f}'\n",
    "         .format(this_alpha, num_coeff_bigger, r2_train, r2_test))\n",
    "    print(linridge.coef_)\n",
    "    print(linridge.intercept_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lasso Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lasso regression linear model intercept: 0.9265930000000001\n",
      "lasso regression linear model coeff:\n",
      "[ 0.  0.  0.  0.  0. -0.  0.  0.  0. -0.  0.]\n",
      "Non-zero features: 0\n",
      "R-squared score (training): 0.000\n",
      "R-squared score (test): -0.013\n",
      "\n",
      "Features with non-zero weight (sorted by absolute magnitude):\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(dfout, OyOriginal,\n",
    "                                                   random_state = 0)\n",
    "\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "linlasso = Lasso(alpha=2.0).fit(X_train_scaled, y_train)\n",
    "\n",
    "print('lasso regression linear model intercept: {}'\n",
    "     .format(linlasso.intercept_))\n",
    "print('lasso regression linear model coeff:\\n{}'\n",
    "     .format(linlasso.coef_))\n",
    "print('Non-zero features: {}'\n",
    "     .format(np.sum(linlasso.coef_ != 0)))\n",
    "print('R-squared score (training): {:.3f}'\n",
    "     .format(linlasso.score(X_train_scaled, y_train)))\n",
    "print('R-squared score (test): {:.3f}\\n'\n",
    "     .format(linlasso.score(X_test_scaled, y_test)))\n",
    "print('Features with non-zero weight (sorted by absolute magnitude):')\n",
    "\n",
    "for e in sorted (list(zip(list(dfout), linlasso.coef_)),\n",
    "                key = lambda e: -abs(e[1])):\n",
    "    if e[1] != 0:\n",
    "        print('\\t{}, {:.3f}'.format(e[0], e[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lasso regression: effect of alpha regularization\n",
      "parameter on number of features kept in final model\n",
      "\n",
      "Alpha = 0.50\n",
      "Features kept: 0, r-squared training: 0.00, r-squared test: -0.01\n",
      "Alpha = 1.00\n",
      "Features kept: 0, r-squared training: 0.00, r-squared test: -0.01\n",
      "Alpha = 2.00\n",
      "Features kept: 0, r-squared training: 0.00, r-squared test: -0.01\n",
      "Alpha = 3.00\n",
      "Features kept: 0, r-squared training: 0.00, r-squared test: -0.01\n",
      "Alpha = 5.00\n",
      "Features kept: 0, r-squared training: 0.00, r-squared test: -0.01\n",
      "Alpha = 10.00\n",
      "Features kept: 0, r-squared training: 0.00, r-squared test: -0.01\n",
      "Alpha = 20.00\n",
      "Features kept: 0, r-squared training: 0.00, r-squared test: -0.01\n",
      "Alpha = 50.00\n",
      "Features kept: 0, r-squared training: 0.00, r-squared test: -0.01\n"
     ]
    }
   ],
   "source": [
    "print('Lasso regression: effect of alpha regularization\\n\\\n",
    "parameter on number of features kept in final model\\n')\n",
    "\n",
    "for alpha in [0.5, 1, 2, 3, 5, 10, 20, 50]:\n",
    "    linlasso = Lasso(alpha).fit(X_train_scaled, y_train)\n",
    "    r2_train = linlasso.score(X_train_scaled, y_train)\n",
    "    r2_test = linlasso.score(X_test_scaled, y_test)\n",
    "    \n",
    "    print('Alpha = {:.2f}\\nFeatures kept: {}, r-squared training: {:.2f}, \\\n",
    "r-squared test: {:.2f}'\n",
    "         .format(alpha, np.sum(linlasso.coef_ != 0), r2_train, r2_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
