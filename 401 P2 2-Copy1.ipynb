{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.optimize import curve_fit\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "df = pd.read_csv('term_project_overlay_data.csv').drop('overlay_error_x', axis = 1, inplace = False)\n",
    "OyOriginal = df[' overlay_error_y']\n",
    "df.drop(' overlay_error_y', axis = 1, inplace = True)\n",
    "dataOriginal = df.values\n",
    "df.rename(columns={' x': 'x'}, inplace = True)\n",
    "dfout = df\n",
    "dfout['x2'] = df['x']*df['x']\n",
    "dfout['y2'] = df['y'] * df['y']\n",
    "dfout['xy'] = df['x'] * df['y']\n",
    "dfout['X2'] = df['X'] * df['X']\n",
    "dfout['Y2'] = df['Y'] * df['Y']\n",
    "dfout['XY'] = df['X'] * df['Y']\n",
    "dfout['0'] = 1\n",
    "dfout = dfout[['0', 'X', 'Y', 'XY', 'X2', 'Y2', 'x', 'y', 'xy', 'x2', 'y2']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ordinary Least Square Method with Training and Test Set Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "linear model intercept: 0.7485286953336125\n",
      "linear model coeff:\n",
      "[ 0.00000000e+00  3.04014130e-03  3.97338613e-03  1.03852304e-05\n",
      "  5.72920217e-06 -1.69748997e-05  1.60371908e-02  1.45566852e-02\n",
      "  2.75898064e-04 -3.65549058e-03  2.72713620e-03]\n",
      "R-squared score (training): 0.457\n",
      "R-squared score (test): 0.141\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(dfout, OyOriginal,\n",
    "                                                   random_state = 0)\n",
    "linreg = LinearRegression().fit(X_train, y_train)\n",
    "\n",
    "print('linear model intercept: {}'\n",
    "     .format(linreg.intercept_))\n",
    "print('linear model coeff:\\n{}'\n",
    "     .format(linreg.coef_))\n",
    "print('R-squared score (training): {:.3f}'\n",
    "     .format(linreg.score(X_train, y_train)))\n",
    "print('R-squared score (test): {:.3f}'\n",
    "     .format(linreg.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ridge Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ridge regression linear model intercept: 0.7484596024496036\n",
      "ridge regression linear model coeff:\n",
      "[ 0.00000000e+00  3.03919844e-03  3.97283637e-03  1.03837731e-05\n",
      "  5.73346762e-06 -1.69738261e-05  1.59955609e-02  1.45452115e-02\n",
      "  2.76051384e-04 -3.65446276e-03  2.72715717e-03]\n",
      "R-squared score (training): 0.457\n",
      "R-squared score (test): 0.141\n",
      "Number of non-zero features: 10\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "X_train, X_test, y_train, y_test = train_test_split(dfout, OyOriginal,\n",
    "                                                   random_state = 0)\n",
    "\n",
    "linridge = Ridge(alpha=20.0).fit(X_train, y_train)\n",
    "\n",
    "print('ridge regression linear model intercept: {}'\n",
    "     .format(linridge.intercept_))\n",
    "print('ridge regression linear model coeff:\\n{}'\n",
    "     .format(linridge.coef_))\n",
    "print('R-squared score (training): {:.3f}'\n",
    "     .format(linridge.score(X_train, y_train)))\n",
    "print('R-squared score (test): {:.3f}'\n",
    "     .format(linridge.score(X_test, y_test)))\n",
    "print('Number of non-zero features: {}'\n",
    "     .format(np.sum(linridge.coef_ != 0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scaled data:\n",
      "ridge regression linear model intercept: 0.24083232615128025\n",
      "ridge regression linear model coeff:\n",
      "[ 0.          0.33502682  0.4021618   0.06921812  0.07011548 -0.1146341\n",
      "  0.11788948  0.17023391  0.02507628 -0.1905958   0.48167654]\n",
      "R-squared score (training): 0.333\n",
      "R-squared score (test): 0.196\n",
      "Number of non-zero features: 10\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "from sklearn.linear_model import Ridge\n",
    "X_train, X_test, y_train, y_test = train_test_split(dfout, OyOriginal,\n",
    "                                                   random_state = 0)\n",
    "\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "linridge = Ridge(alpha=20.0).fit(X_train_scaled, y_train)\n",
    "\n",
    "print('Scaled data:')\n",
    "print('ridge regression linear model intercept: {}'\n",
    "     .format(linridge.intercept_))\n",
    "print('ridge regression linear model coeff:\\n{}'\n",
    "     .format(linridge.coef_))\n",
    "print('R-squared score (training): {:.3f}'\n",
    "     .format(linridge.score(X_train_scaled, y_train)))\n",
    "print('R-squared score (test): {:.3f}'\n",
    "     .format(linridge.score(X_test_scaled, y_test)))\n",
    "print('Number of non-zero features: {}'\n",
    "     .format(np.sum(linridge.coef_ != 0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ridge regression: effect of alpha regularization parameter\n",
      "\n",
      "Alpha = 0.00\n",
      "num abs(coeff) > 0: 10, r-squared training: 0.46, r-squared test: 0.14\n",
      "Alpha = 5.00\n",
      "num abs(coeff) > 0: 10, r-squared training: 0.43, r-squared test: 0.20\n",
      "Alpha = 10.00\n",
      "num abs(coeff) > 0: 10, r-squared training: 0.40, r-squared test: 0.21\n",
      "Alpha = 15.00\n",
      "num abs(coeff) > 0: 10, r-squared training: 0.36, r-squared test: 0.20\n",
      "Alpha = 20.00\n",
      "num abs(coeff) > 0: 10, r-squared training: 0.33, r-squared test: 0.20\n",
      "Alpha = 25.00\n",
      "num abs(coeff) > 0: 10, r-squared training: 0.31, r-squared test: 0.19\n",
      "Alpha = 30.00\n",
      "num abs(coeff) > 0: 10, r-squared training: 0.29, r-squared test: 0.18\n",
      "Alpha = 35.00\n",
      "num abs(coeff) > 0: 10, r-squared training: 0.27, r-squared test: 0.17\n",
      "Alpha = 40.00\n",
      "num abs(coeff) > 0: 10, r-squared training: 0.25, r-squared test: 0.16\n",
      "Alpha = 45.00\n",
      "num abs(coeff) > 0: 10, r-squared training: 0.24, r-squared test: 0.15\n"
     ]
    }
   ],
   "source": [
    "print('Ridge regression: effect of alpha regularization parameter\\n')\n",
    "for this_alpha in range(0, 50, 5):\n",
    "    linridge = Ridge(alpha = this_alpha).fit(X_train_scaled, y_train)\n",
    "    r2_train = linridge.score(X_train_scaled, y_train)\n",
    "    r2_test = linridge.score(X_test_scaled, y_test)\n",
    "    num_coeff_bigger = np.sum(abs(linridge.coef_) > 0)\n",
    "    print('Alpha = {:.2f}\\nnum abs(coeff) > 0: {}, \\\n",
    "r-squared training: {:.2f}, r-squared test: {:.2f}'\n",
    "         .format(this_alpha, num_coeff_bigger, r2_train, r2_test))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lasso Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lasso regression linear model intercept: 0.9265930000000001\n",
      "lasso regression linear model coeff:\n",
      "[ 0.  0.  0.  0.  0. -0.  0.  0.  0. -0.  0.]\n",
      "Non-zero features: 0\n",
      "R-squared score (training): 0.000\n",
      "R-squared score (test): -0.013\n",
      "\n",
      "Features with non-zero weight (sorted by absolute magnitude):\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(dfout, OyOriginal,\n",
    "                                                   random_state = 0)\n",
    "\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "linlasso = Lasso(alpha=2.0).fit(X_train_scaled, y_train)\n",
    "\n",
    "print('lasso regression linear model intercept: {}'\n",
    "     .format(linlasso.intercept_))\n",
    "print('lasso regression linear model coeff:\\n{}'\n",
    "     .format(linlasso.coef_))\n",
    "print('Non-zero features: {}'\n",
    "     .format(np.sum(linlasso.coef_ != 0)))\n",
    "print('R-squared score (training): {:.3f}'\n",
    "     .format(linlasso.score(X_train_scaled, y_train)))\n",
    "print('R-squared score (test): {:.3f}\\n'\n",
    "     .format(linlasso.score(X_test_scaled, y_test)))\n",
    "print('Features with non-zero weight (sorted by absolute magnitude):')\n",
    "\n",
    "for e in sorted (list(zip(list(dfout), linlasso.coef_)),\n",
    "                key = lambda e: -abs(e[1])):\n",
    "    if e[1] != 0:\n",
    "        print('\\t{}, {:.3f}'.format(e[0], e[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lasso regression: effect of alpha regularization\n",
      "parameter on number of features kept in final model\n",
      "\n",
      "Alpha = 0.50\n",
      "Features kept: 0, r-squared training: 0.00, r-squared test: -0.01\n",
      "Alpha = 1.00\n",
      "Features kept: 0, r-squared training: 0.00, r-squared test: -0.01\n",
      "Alpha = 2.00\n",
      "Features kept: 0, r-squared training: 0.00, r-squared test: -0.01\n",
      "Alpha = 3.00\n",
      "Features kept: 0, r-squared training: 0.00, r-squared test: -0.01\n",
      "Alpha = 5.00\n",
      "Features kept: 0, r-squared training: 0.00, r-squared test: -0.01\n",
      "Alpha = 10.00\n",
      "Features kept: 0, r-squared training: 0.00, r-squared test: -0.01\n",
      "Alpha = 20.00\n",
      "Features kept: 0, r-squared training: 0.00, r-squared test: -0.01\n",
      "Alpha = 50.00\n",
      "Features kept: 0, r-squared training: 0.00, r-squared test: -0.01\n"
     ]
    }
   ],
   "source": [
    "print('Lasso regression: effect of alpha regularization\\n\\\n",
    "parameter on number of features kept in final model\\n')\n",
    "\n",
    "for alpha in [0.5, 1, 2, 3, 5, 10, 20, 50]:\n",
    "    linlasso = Lasso(alpha).fit(X_train_scaled, y_train)\n",
    "    r2_train = linlasso.score(X_train_scaled, y_train)\n",
    "    r2_test = linlasso.score(X_test_scaled, y_test)\n",
    "    \n",
    "    print('Alpha = {:.2f}\\nFeatures kept: {}, r-squared training: {:.2f}, \\\n",
    "r-squared test: {:.2f}'\n",
    "         .format(alpha, np.sum(linlasso.coef_ != 0), r2_train, r2_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
